{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as s\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "import pickle\n",
    "import imblearn\n",
    "# from sklearn.ensemble import forest\n",
    "plt.rcParams[\"figure.figsize\"]=(12,8)\n",
    "import plotnine as p9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
       "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
       "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
       "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
       "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
       "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
       "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop('Unnamed: 32', axis=1) # specify the axis that the name applies to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diagnosis = df.diagnosis.astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"diagnosis\", axis=1) # just saying which axis again\n",
    "Y = df[\"diagnosis\"] # this is just a series now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X.columns # if we do type(col), it's an Index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum() # this covers every column in the df. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rangenorm(x):\n",
    "    return (x - x.mean())/(x.max() - x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = X.apply(rangenorm) # this worked.  Apply goes column-wise by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = pd.concat([df_norm, Y], axis = 1) # need to pass dfs as a list, and specify the axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### skip for now\n",
    "X_norm = df_norm.drop(\"diagnosis\", axis=1)\n",
    "Y_norm = df_norm[\"diagnosis\"]\n",
    "col = X_norm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le.fit(Y_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_norm = le.transform(Y_norm) # converts to a numpy nd array of ones and zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_norm = pd.DataFrame(Y_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FitModel(X, Y, algo_name, algorithm, gridSearchParams, cv):\n",
    "    \"\"\"Split, take a dict of gridsearch params,\"\"\"\n",
    "    np.random.seed(10)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "\n",
    "    train = pd.concat([y_train, x_train], axis=1)\n",
    "    train.to_csv(\"./train.csv\", index=False, header=False)\n",
    "    y_train.to_csv(\"./Y-train.csv\", index=False, header=False)\n",
    "    \n",
    "    test = pd.concat([y_test, x_test], axis=1)\n",
    "    test.to_csv(\"./test.csv\", index=False, header=False)\n",
    "    y_test.to_csv(\"./Y-test.csv\", index=False, header=False)\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=algorithm,\n",
    "        param_grid=gridSearchParams,\n",
    "        cv=cv,\n",
    "        scoring='accuracy',\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    grid_result=grid.fit(x_train, y_train)\n",
    "    best_params=grid_result.best_params_\n",
    "    pred = grid_result.predict(x_test)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "\n",
    "    print(pred)\n",
    "    pickle.dump(grid_result, open(algo_name+\".pkl\", \"wb\"))\n",
    "\n",
    "    print('Best Params :',best_params)\n",
    "    print('Classification Report :',classification_report(y_test,pred))\n",
    "    print('Accuracy Score : ' + str(accuracy_score(y_test,pred)))\n",
    "    print('Confusion Matrix : \\n', cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For SVM, put in four values of possible C and 7 for gamma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n",
      "[1 0 0 1 0 1 0 0 1 1 0 0 1 0 1 1 0 0 0 0 1 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0\n",
      " 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0\n",
      " 0 1 1]\n",
      "Best Params : {'C': 1, 'gamma': 1}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        75\n",
      "           1       0.93      1.00      0.96        39\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.96      0.98      0.97       114\n",
      "weighted avg       0.98      0.97      0.97       114\n",
      "\n",
      "Accuracy Score : 0.9736842105263158\n",
      "Confusion Matrix : \n",
      " [[72  3]\n",
      " [ 0 39]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophermartin/DocumentsNoCloud/repos/cmcode/deployml/predict_breast/demo/venvbc/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "param ={\n",
    "            'C': [0.1, 1, 100, 1000],\n",
    "            'gamma': [0.0001, 0.001, 0.005, 0.1, 1, 3, 5]\n",
    "        }\n",
    "FitModel(X_norm,Y_norm,'SVC_norm',SVC(),param,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "X_res , Y_res = sm.fit_resample(X_norm,Y_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(714, 31)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    357\n",
       "1    357\n",
       "dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_res.value_counts()\n",
    "# Y_norm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophermartin/DocumentsNoCloud/repos/cmcode/deployml/predict_breast/demo/venvbc/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "/Users/christophermartin/DocumentsNoCloud/repos/cmcode/deployml/predict_breast/demo/venvbc/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:27:17] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[1 0 0 1 0 0 0 0 1 1 0 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1 0 0 0 0\n",
      " 0 1 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0\n",
      " 0 1 1]\n",
      "Best Params : {'n_estimators': 500}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98        75\n",
      "           1       0.95      0.97      0.96        39\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n",
      "Accuracy Score : 0.9736842105263158\n",
      "Confusion Matrix : \n",
      " [[73  2]\n",
      " [ 1 38]]\n"
     ]
    }
   ],
   "source": [
    "param ={\n",
    "            'n_estimators': [100, 500, 1000, 2000],\n",
    "           \n",
    "        }\n",
    "FitModel(X_norm,Y_norm,'XGBoost_norm',XGBClassifier(),param,cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pickled model in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"XGBoost_norm.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = loaded_model.predict(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9901960784313726"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([x==y for x,y in zip(pred1, Y_res.squeeze())])/len(pred1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:27:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophermartin/DocumentsNoCloud/repos/cmcode/deployml/predict_breast/demo/venvbc/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n"
     ]
    }
   ],
   "source": [
    "xgbc = XGBClassifier(n_estimators=100)\n",
    "fit = xgbc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = fit.score(x_test, y_test)\n",
    "predict = fit.predict(x_test)\n",
    "cmatrix = confusion_matrix(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[73,  2],\n",
       "       [ 1, 38]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9736842105263158"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = xgbc.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature id (0.593)\n",
      "feature radius_mean (0.118)\n",
      "feature texture_mean (0.067)\n",
      "feature perimeter_mean (0.037)\n",
      "feature area_mean (0.023)\n",
      "feature smoothness_mean (0.019)\n",
      "feature compactness_mean (0.017)\n",
      "feature concavity_mean (0.014)\n",
      "feature concave points_mean (0.013)\n",
      "feature symmetry_mean (0.010)\n",
      "feature fractal_dimension_mean (0.010)\n",
      "feature radius_se (0.009)\n",
      "feature texture_se (0.008)\n",
      "feature perimeter_se (0.008)\n",
      "feature area_se (0.007)\n",
      "feature smoothness_se (0.007)\n",
      "feature compactness_se (0.006)\n",
      "feature concavity_se (0.005)\n",
      "feature concave points_se (0.004)\n",
      "feature symmetry_se (0.004)\n",
      "feature fractal_dimension_se (0.004)\n",
      "feature radius_worst (0.004)\n",
      "feature texture_worst (0.003)\n",
      "feature perimeter_worst (0.003)\n",
      "feature area_worst (0.002)\n",
      "feature smoothness_worst (0.002)\n",
      "feature compactness_worst (0.001)\n",
      "feature concavity_worst (0.000)\n",
      "feature concave points_worst (0.000)\n",
      "feature symmetry_worst (0.000)\n",
      "feature fractal_dimension_worst (0.000)\n"
     ]
    }
   ],
   "source": [
    "for f in range(X.shape[1]):\n",
    "    print(\"feature {} ({:.3f})\".format(list(X)[f], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = pd.DataFrame({\"Feature\":list(X),\n",
    "                        \"GiniImportance\":importances[indices]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp.index = feat_imp.Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_to_keep = feat_imp.iloc[1:15].index # we just want the names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pandas.core.indexes.base.Index,\n",
       " Index(['radius_mean', 'texture_mean', 'perimeter_mean', 'area_mean',\n",
       "        'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
       "        'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
       "        'radius_se', 'texture_se', 'perimeter_se', 'area_se'],\n",
       "       dtype='object', name='Feature'))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feat_to_keep), feat_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res= pd.DataFrame(X_res)\n",
    "Y_res = pd.DataFrame(Y_res)\n",
    "X_res.columns = X_norm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[17:28:29] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[1 1 0 1 0 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 0 0 1 0 1 1 0 0 0 1 1 1 1 1 1\n",
      " 1 0 0 0 0 1 0 1 1 1 1 0 1 1 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 0 0 0 0 0 0 0 0 1\n",
      " 0 1 0 0 1 0 1 1 1 0 0 1 1 0 0 0 0 0 0 1 0 1 1 0 0 1 0 0 0 0 0 0]\n",
      "Best Params : {'n_estimators': 100}\n",
      "Classification Report :               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98        68\n",
      "           1       0.97      0.99      0.98        75\n",
      "\n",
      "    accuracy                           0.98       143\n",
      "   macro avg       0.98      0.98      0.98       143\n",
      "weighted avg       0.98      0.98      0.98       143\n",
      "\n",
      "Accuracy Score : 0.9790209790209791\n",
      "Confusion Matrix : \n",
      " [[66  2]\n",
      " [ 1 74]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophermartin/DocumentsNoCloud/repos/cmcode/deployml/predict_breast/demo/venvbc/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "/Users/christophermartin/DocumentsNoCloud/repos/cmcode/deployml/predict_breast/demo/venvbc/lib/python3.8/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "param ={\n",
    "            'n_estimators': [100, 500, 1000, 2000],\n",
    "           \n",
    "        }\n",
    "FitModel(X_res[feat_to_keep],Y_res,'XGBoost',XGBClassifier(),param,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9957983193277311"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model2 = pickle.load(open(\"XGBoost.pkl\",\"rb\"))\n",
    "pred2 = loaded_model2.predict(X_res[feat_to_keep])\n",
    "sum([x==y for x,y in zip(pred2, Y_res.squeeze())])/len(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvbc",
   "language": "python",
   "name": "venvbc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
